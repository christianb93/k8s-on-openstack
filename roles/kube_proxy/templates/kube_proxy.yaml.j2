# Based on configuration files at
# https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/kube-proxy
# and 
# https://github.com/kubernetes/kubernetes/blob/master/cmd/kubeadm/app/phases/addons/proxy/manifests.go
#
# Authentication for the kube-proxy is a bit tricky. We cannot simply use service accounts without further ado,
# as the in-cluster configuration when using the standard Go client directs API requests to the service IP of the cluster 
# (i.e. the first IP address of the service IP range on which the API server itself will be reachable). To make this redirection
# work, however, we need a running kube-proxy, so this is again a bit of a chicken-and-egg challenge. We follow the same approach
# that kubeadm uses - we bind a service account to the pod so that the volumes with the corresponding secrets are mounted, and
# then use a kubeconfig file which simply references these secrets, but contains the correct IP address of the API server
#
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kube-proxy
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-proxy-config
  namespace: kube-system
data:
  kubeconfig: |
    apiVersion: v1
    clusters:
    - cluster:
        certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        server: "https://{{hostvars.master.mgmt_ip}}:6443"
      name: {{cluster_name}}
    contexts:
    - context:
        cluster: {{cluster_name}}
        user: default
      name: {{cluster_name}}-context
    current-context: {{cluster_name}}-context
    kind: Config
    preferences: {}
    users:
    - name: default
      user:
        tokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token  
  kube-proxy-config: |
    kind: KubeProxyConfiguration
    apiVersion: kubeproxy.config.k8s.io/v1alpha1
    clientConnection:
      kubeconfig: "/etc/kubernetes/conf/kubeconfig"
    mode: "iptables"
    clusterCIDR: "{{cluster_cidr}}"    

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: system:kube-proxy
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
subjects:
  - kind: ServiceAccount
    name: kube-proxy
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: system:node-proxier
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    k8s-app: kube-proxy
    addonmanager.kubernetes.io/mode: Reconcile
  name: kube-proxy
  namespace: kube-system
spec:
  selector:
    matchLabels:
      k8s-app: kube-proxy
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 10%
  template:
    metadata:
      labels:
        k8s-app: kube-proxy
    spec:
      hostNetwork: true
      tolerations:
      - operator: Exists
        effect: NoSchedule
      containers:
      - name: kube-proxy
        image: "k8s.gcr.io/kube-proxy-amd64:v1.17.1"
        # image: "busybox"
        command:
        - /bin/sh
        - -c
        - kube-proxy --config /etc/kubernetes/conf/kube-proxy-config
        #- sleep 10000
        env:
        - name: NODE_NAME
          valueFrom:
             fieldRef:
                 fieldPath: spec.nodeName
        securityContext:
          privileged: true                 
        volumeMounts:
        - mountPath: /run/xtables.lock
          name: xtables-lock
          readOnly: false
        - mountPath: /lib/modules
          name: lib-modules
          readOnly: true
        - mountPath: /etc/kubernetes/conf
          name: kube-conf
          readOnly: true
      volumes:
      - name: xtables-lock
        hostPath:
         path: /run/xtables.lock
         type: FileOrCreate
      - name: lib-modules
        hostPath:
          path: /lib/modules
      - name: kube-conf
        configMap:
          name: kube-proxy-config
      serviceAccountName: kube-proxy
